{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkhbcX1-fmnG",
        "outputId": "6c394f46-96b4-4d6a-9a43-b1d2ee726542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = \"/content/Creditcard_data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Check class imbalance\n",
        "print(data['Class'].value_counts())\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# Apply SMOTE (Oversampling)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Verify balanced dataset\n",
        "print(y_balanced.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of creating samples with different sizes\n",
        "sample_sizes = [0.2, 0.4, 0.6, 0.8, None]  # Using None for 100% of the data\n",
        "samples = []\n",
        "\n",
        "for size in sample_sizes:\n",
        "    if size is None:\n",
        "        # Use the entire dataset\n",
        "        samples.append((X_balanced, y_balanced))\n",
        "    else:\n",
        "        # Split dataset\n",
        "        sample_X, _, sample_y, _ = train_test_split(X_balanced, y_balanced, train_size=size, random_state=42)\n",
        "        samples.append((sample_X, sample_y))\n"
      ],
      "metadata": {
        "id": "FLDMJ7xMgIlS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Initialize sampling techniques\n",
        "sampling_methods = {\n",
        "    \"RandomOversampling\": RandomOverSampler(),\n",
        "    \"SMOTE\": SMOTE(),\n",
        "    \"RandomUndersampling\": RandomUnderSampler(),\n",
        "    \"NearMiss\": NearMiss(),\n",
        "}\n",
        "\n",
        "# Apply sampling techniques\n",
        "sampled_data = {}\n",
        "\n",
        "for method, sampler in sampling_methods.items():\n",
        "    X_sampled, y_sampled = sampler.fit_resample(X_balanced, y_balanced)\n",
        "    sampled_data[method] = (X_sampled, y_sampled)\n"
      ],
      "metadata": {
        "id": "0we6IfYBghx3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "models = {\n",
        "    \"M1\": RandomForestClassifier(),\n",
        "    # Add other models like SVM, Logistic Regression, etc., for M2, M3, M4, M5\n",
        "}\n",
        "\n",
        "# Train and evaluate models on sampled data\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    for method, (X_sampled, y_sampled) in sampled_data.items():\n",
        "        # Split sampled data into train and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate accuracy\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[(model_name, method)] = acc\n"
      ],
      "metadata": {
        "id": "KqO-WHq_gjTg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best sampling technique for each model\n",
        "best_results = {}\n",
        "\n",
        "for model_name in models.keys():\n",
        "    best_method = max(\n",
        "        [(method, acc) for (m, method), acc in results.items() if m == model_name],\n",
        "        key=lambda x: x[1]\n",
        "    )\n",
        "    best_results[model_name] = best_method\n",
        "\n",
        "# Display best results\n",
        "for model, (method, acc) in best_results.items():\n",
        "    print(f\"Model {model}: Best Sampling Technique = {method}, Accuracy = {acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZdvUJ7sgonn",
        "outputId": "8d82e78f-ebd0-445a-ab09-cc1b13883d0d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model M1: Best Sampling Technique = RandomUndersampling, Accuracy = 1.00\n"
          ]
        }
      ]
    }
  ]
}